{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the reference to the dataset I am using [Alzheimer’s Prediction Dataset (Global)]: https://www.kaggle.com/datasets/ankushpanday1/alzheimers-prediction-dataset-global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to load the dataset using pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- LOADING DATASET -------\n",
      "Reading 'alzheimers_data.csv' into a pandas DataFrame...\n",
      "Dataset loaded. Number of rows, columns: (74283, 25)\n"
     ]
    }
   ],
   "source": [
    "print(\"------- LOADING DATASET -------\")\n",
    "print(\"Reading 'alzheimers_data.csv' into a pandas DataFrame...\")\n",
    "df = pd.read_csv(\"alzheimers_data.csv\")\n",
    "print(\"Dataset loaded. Number of rows, columns:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now select 10 features from the dataset in addition to the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are the 10 features:\n",
    "    1) Age (numeric)\n",
    "    2) Gender (categorical)\n",
    "    3) Education Level (numeric-ish)\n",
    "    4) BMI (numeric)\n",
    "    5) Physical Activity Level (categorical)\n",
    "    6) Smoking Status (categorical)\n",
    "    7) Diabetes (categorical)\n",
    "    8) Hypertension (categorical)\n",
    "    9) Cholesterol Level (categorical)\n",
    "    10) Family History of Alzheimer’s (categorical)\n",
    "    Target: Alzheimer’s Diagnosis (Yes/No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- SELECTING 10 FEATURES + TARGET -------\n",
      "Selected columns: ['Age', 'Gender', 'Education Level', 'BMI', 'Physical Activity Level', 'Smoking Status', 'Diabetes', 'Hypertension', 'Cholesterol Level', 'Family History of Alzheimer’s', 'Alzheimer’s Diagnosis']\n"
     ]
    }
   ],
   "source": [
    "print(\"------- SELECTING 10 FEATURES + TARGET -------\")\n",
    "\n",
    "selected_columns = [\n",
    "        \"Age\",\n",
    "        \"Gender\",\n",
    "        \"Education Level\",\n",
    "        \"BMI\",\n",
    "        \"Physical Activity Level\",\n",
    "        \"Smoking Status\",\n",
    "        \"Diabetes\",\n",
    "        \"Hypertension\",\n",
    "        \"Cholesterol Level\",\n",
    "        \"Family History of Alzheimer’s\",\n",
    "        \"Alzheimer’s Diagnosis\"  # target\n",
    "    ]\n",
    "\n",
    "# Subset the DataFrame\n",
    "df = df[selected_columns].copy()\n",
    "print(\"Selected columns:\", selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ENCODING CATEGORICAL FEATURES -------\n",
      "Encoding column: Gender\n",
      "Encoding column: Physical Activity Level\n",
      "Encoding column: Smoking Status\n",
      "Encoding column: Diabetes\n",
      "Encoding column: Hypertension\n",
      "Encoding column: Cholesterol Level\n",
      "Encoding column: Family History of Alzheimer’s\n",
      "Encoding column: Alzheimer’s Diagnosis\n",
      "Feature shape: (74283, 10)  | Target shape: (74283,)\n"
     ]
    }
   ],
   "source": [
    "print(\"------- ENCODING CATEGORICAL FEATURES -------\")\n",
    "    # We'll label-encode columns that are categorical:\n",
    "    # (Gender, Physical Activity Level, Smoking Status,\n",
    "    #  Diabetes, Hypertension, Cholesterol Level,\n",
    "    #  Family History of Alzheimer’s, Alzheimer’s Diagnosis)\n",
    "categorical_cols = [\n",
    "    \"Gender\",\n",
    "    \"Physical Activity Level\",\n",
    "    \"Smoking Status\",\n",
    "    \"Diabetes\",\n",
    "    \"Hypertension\",\n",
    "    \"Cholesterol Level\",\n",
    "    \"Family History of Alzheimer’s\",\n",
    "    \"Alzheimer’s Diagnosis\"\n",
    "]\n",
    "    \n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    print(f\"Encoding column: {col}\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Create separate feature and target arrays\n",
    "feature_cols = selected_columns[:-1]  # all but the last \n",
    "target_col   = selected_columns[-1]   # the last one: \"Alzheimer’s Diagnosis\"\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(\"Feature shape:\", X.shape, \" | Target shape:\", y.shape) # no y-coordinate for shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a balanced test set for each class of 100 and leave the rest for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- CREATING BALANCED TEST SET -------\n",
      "Test set size: 200 | Class 0 in test: 100 | Class 1 in test: 100\n",
      "Training set size: 74083\n"
     ]
    }
   ],
   "source": [
    "print(\"------- CREATING BALANCED TEST SET -------\")\n",
    "class0_indices = np.where(y == 0)[0]  # \"No\"\n",
    "class1_indices = np.where(y == 1)[0]  # \"Yes\"\n",
    "\n",
    "np.random.shuffle(class0_indices)\n",
    "np.random.shuffle(class1_indices)\n",
    "\n",
    "# Take 100 from each for test\n",
    "test_class0 = class0_indices[:100]\n",
    "test_class1 = class1_indices[:100]\n",
    "\n",
    "# The remaining for training\n",
    "train_class0 = class0_indices[100:]\n",
    "train_class1 = class1_indices[100:]\n",
    "\n",
    "# Build the train/test sets\n",
    "test_indices = np.concatenate((test_class0, test_class1))\n",
    "train_indices = np.concatenate((train_class0, train_class1))\n",
    "np.random.shuffle(test_indices)\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "X_test = X[test_indices]\n",
    "y_test = y[test_indices]\n",
    "    \n",
    "X_train_full = X[train_indices]\n",
    "y_train_full = y[train_indices]\n",
    "\n",
    "print(\"Test set size:\", len(X_test),\n",
    "    \"| Class 0 in test:\", len(test_class0),\n",
    "    \"| Class 1 in test:\", len(test_class1))\n",
    "print(\"Training set size:\", len(X_train_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalance the remaining training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ UNBALANCING TRAINING DATA ------\n",
      "Desired class-0 (No) count: 43570\n",
      "Desired class-1 (Yes) count: 30713\n",
      "Unbalanced training set size: 74283 | Class 0 in unbalanced set: 43570 | Class 1 in unbalanced set: 30713\n"
     ]
    }
   ],
   "source": [
    "print(\"------ UNBALANCING TRAINING DATA ------\")\n",
    "# Suppose we want 43570 from class0 (No) and 30713 from class1 (Yes).\n",
    "desired_class0 = 43570 \n",
    "desired_class1 = 30713\n",
    "\n",
    "# Sample/replicate from our training set as needed\n",
    "print(\"Desired class-0 (No) count:\", desired_class0)\n",
    "print(\"Desired class-1 (Yes) count:\", desired_class1)\n",
    "\n",
    "def get_unbalanced_indices(train_cls_indices, desired_count):\n",
    "    if len(train_cls_indices) < desired_count:\n",
    "        # Replicate some\n",
    "        replicate_factor = (desired_count // len(train_cls_indices)) + 1\n",
    "        extended = np.tile(train_cls_indices, replicate_factor)\n",
    "        np.random.shuffle(extended)\n",
    "        return extended[:desired_count]\n",
    "    else:\n",
    "        np.random.shuffle(train_cls_indices)\n",
    "        return train_cls_indices[:desired_count]\n",
    "\n",
    "train_class0_bal = get_unbalanced_indices(train_class0, desired_class0)\n",
    "train_class1_bal = get_unbalanced_indices(train_class1, desired_class1)\n",
    "\n",
    "unbalanced_train_indices = np.concatenate((train_class0_bal, train_class1_bal))\n",
    "np.random.shuffle(unbalanced_train_indices)\n",
    "\n",
    "X_train = X[unbalanced_train_indices]\n",
    "y_train = y[unbalanced_train_indices]\n",
    "\n",
    "print(\"Unbalanced training set size:\", len(X_train),\n",
    "    \"| Class 0 in unbalanced set:\", sum(y_train == 0),\n",
    "    \"| Class 1 in unbalanced set:\", sum(y_train == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly relabel 5% of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ FLIPPING 5% OF LABELS IN THE TRAINING SET ------\n",
      "Flipped 2178 '0' labels to '1' and 1535 '1' labels to '0'.\n"
     ]
    }
   ],
   "source": [
    "print(\"------ FLIPPING 5% OF LABELS IN THE TRAINING SET ------\")\n",
    "def flip_labels(y_array, flip_fraction=0.05):\n",
    "    idx_class0 = np.where(y_array == 0)[0]\n",
    "    idx_class1 = np.where(y_array == 1)[0]\n",
    "\n",
    "    n0 = len(idx_class0)\n",
    "    n1 = len(idx_class1)\n",
    "\n",
    "    flip_n0 = int(flip_fraction * n0)  # Flip how many 0 -> 1\n",
    "    flip_n1 = int(flip_fraction * n1)  # Flip how many 1 -> 0\n",
    "\n",
    "    flip_indices_0 = np.random.choice(idx_class0, size=flip_n0, replace=False)\n",
    "    flip_indices_1 = np.random.choice(idx_class1, size=flip_n1, replace=False)\n",
    "\n",
    "    # Flip them in-place\n",
    "    y_array[flip_indices_0] = 1\n",
    "    y_array[flip_indices_1] = 0\n",
    "\n",
    "    print(f\"Flipped {len(flip_indices_0)} '0' labels to '1' and \"\n",
    "        f\"{len(flip_indices_1)} '1' labels to '0'.\")\n",
    "\n",
    "flip_labels(y_train, flip_fraction=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to build our shallow feed-foward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- BUILDING A SHALLOW FEED-FORWARD NETWORK ------\n",
      "Model architecture: 10 -> 20 -> 1 (sigmoid activations).\n"
     ]
    }
   ],
   "source": [
    "print(\"------- BUILDING A SHALLOW FEED-FORWARD NETWORK ------\")\n",
    "# We have 10 input features, use a single hidden layer with 2*input_dim = 20 units.\n",
    "# Sigmoid activation on hidden layer, and sigmoid on the output layer for binary classification.\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 2 * input_dim  # 2x the number of input features\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Build and compile a simple 2-layer (1 hidden layer) neural network.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    model.add(layers.Dense(hidden_dim, activation='sigmoid'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"Model architecture: 10 -> 20 -> 1 (sigmoid activations).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
